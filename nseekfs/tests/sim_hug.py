import numpy as np
import time
import os
from sentence_transformers import SentenceTransformer
from nseekfs import prepare_engine_from_embeddings, PySearchEngine

# ========================
# Simular engenheiro
# ========================
num_vectors = 500_000
dims = 384
base_path = "engenheiro_data"
level = "f32"
bin_path = f"{base_path}_{level}_ann.bin"
sentences = [f"Frase do engenheiro {i}" for i in range(num_vectors)]

print(f"ğŸ“¦ A gerar {num_vectors:,} embeddings externos (simulados)...")
t0 = time.time()
data = np.random.randn(num_vectors, dims).astype(np.float32)
print(f"âœ… Embeddings prontos [{time.time() - t0:.2f}s]")

# ========================
# Criar bin a partir dos embeddings
# ========================
print("\nğŸ’¾ A criar binÃ¡rio diretamente a partir de RAM...")
t0 = time.time()
path = prepare_engine_from_embeddings(
    data,
    base_path=base_path,
    precision=level,
    normalize=True,
    use_ann=False
)
print(f"âœ… BinÃ¡rio guardado em: {path} [{time.time() - t0:.2f}s]")

# ========================
# Criar engine a partir do .bin
# ========================
print("\nâš™ï¸ A carregar engine a partir do binÃ¡rio...")
t0 = time.time()
engine = PySearchEngine(path, use_ann=True)
print(f"âœ… Engine carregada do binÃ¡rio [{time.time() - t0:.2f}s]")

# ========================
# Query 1: vetor direto (ex: embeddings recebidos por API)
# ========================
print("\nğŸ” Query 1: vetor direto (gerado fora)")
query_vec = np.random.randn(dims).astype(np.float32)
t0 = time.time()
results = engine.top_k_query(query_vec.tolist(), 3)
print(f"ğŸ•’ Query direta: {time.time() - t0:.3f}s")
for i, (idx, score) in enumerate(results, 1):
    print(f"  {i}. idx={idx} | score={score:.4f} | texto={sentences[idx]}")

# ========================
# Query 2: por Ã­ndice (ex: base pessoal do engenheiro)
# ========================
print("\nğŸ” Query 2: por Ã­ndice")
t0 = time.time()
results = engine.top_k_similar(123456, 3)
print(f"ğŸ•’ Query por Ã­ndice: {time.time() - t0:.3f}s")
for i, (idx, score) in enumerate(results, 1):
    print(f"  {i}. idx={idx} | score={score:.4f} | texto={sentences[idx]}")

# ========================
# Query 3: por texto (via HuggingFace)
# ========================
print("\nğŸ” Query 3: por texto (usando HuggingFace)")
try:
    model = SentenceTransformer("all-MiniLM-L6-v2")
    query_text = "SugestÃ£o tÃ©cnica avanÃ§ada para modelos de vetores"
    query_vec = model.encode([query_text], normalize_embeddings=True)[0]
    t0 = time.time()
    results = engine.top_k_query(query_vec.tolist(), 3)
    print(f"ğŸ•’ Query por texto: {time.time() - t0:.3f}s")
    for i, (idx, score) in enumerate(results, 1):
        print(f"  {i}. idx={idx} | score={score:.4f} | texto={sentences[idx]}")
except ImportError:
    print("âš ï¸ sentence-transformers nÃ£o instalado")
